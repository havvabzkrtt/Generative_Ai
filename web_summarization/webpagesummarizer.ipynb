{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\havva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\havva\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")  # Bu satır, Hugging Face Transformers kütüphanesindeki önceden eğitilmiş bir metin özetleme modelinin kullanılabilmesi için bir pipeline başlatır.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit UI\n",
    "st.title(\"Webpage to Bullet Points Summarizer\")\n",
    "\n",
    "url = \"https://blog.langchain.dev/langchain-and-scrimba-partner-to-help-web-devs-become-ai-engineers/\"\n",
    "#url = st.text_input(\"Enter webpage URL:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangChain is partnering with Scrimba, a code-learning platform with over a million users \n",
      "Through their interactive video format known as scrims, they enable developers to grow their skills in a more fun and immersive way than regular video courses \n",
      "The course will be fully project-based, so you’ll learn the concepts while creating a real-world application \n",
      "Launch is set to mid-October, but a sneak peek of it has already been released .\n"
     ]
    }
   ],
   "source": [
    "# Eğer kullanıcı bir URL girdiyse, requests kütüphanesi ile bu URL'den web sayfasının içeriği çekilir. Ardından, BeautifulSoup kullanılarak sayfadaki paragraflar (<p> etiketi içerenler) bulunur ve birleştirilerek bir metin oluşturulur. Bu metin, daha sonra özetleme modeline gönderilir ve özeti alınır.\n",
    "if url:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    \n",
    "    # Combine all the text from the <p> tags\n",
    "    content = ' '.join([para.text for para in paragraphs])\n",
    "    \n",
    "    # Summarize the content\n",
    "    summary = summarizer(content, max_length=200, min_length=50, do_sample=False)[0]['summary_text']\n",
    "    \n",
    "    st.subheader(\"Summarized Content:\")\n",
    "    st.write(summary)\n",
    "    \n",
    "    st.subheader(\"Bullet Points:\")\n",
    "    # Basit olması için özeti cümlelere bölüyoruz ve her birini \"point\" olarak ele alıyoruz.\n",
    "    bullet_points = summary.split('. ')\n",
    "    for point in bullet_points:\n",
    "        st.write(f\"- {point}\")\n",
    "        print(point)\n",
    "\n",
    "# Örnek link\n",
    "# https://blog.langchain.dev/langchain-and-scrimba-partner-to-help-web-devs-become-ai-engineers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer_func(url):\n",
    "    if url:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        \n",
    "        # Combine all the text from the <p> tags\n",
    "        content = ' '.join([para.text for para in paragraphs])\n",
    "        \n",
    "        # Summarize the content\n",
    "        summary = summarizer(content, max_length=200, min_length=50, do_sample=False)[0]['summary_text']\n",
    "        \n",
    "        st.subheader(\"Summarized Content:\")\n",
    "        st.write(summary)\n",
    "        \n",
    "        st.subheader(\"Bullet Points:\")\n",
    "        # Basit olması için özeti cümlelere bölüyoruz ve her birini \"point\" olarak ele alıyoruz.\n",
    "        bullet_points = summary.split('. ')\n",
    "        for point in bullet_points:\n",
    "            st.write(f\"- {point}\")\n",
    "            print(point)\n",
    "    \n",
    "    return bullet_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Launch is set to mid-October, but a sneak peek of it has already been released .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_url = \"https://blog.langchain.dev/langchain-and-scrimba-partner-to-help-web-devs-become-ai-engineers/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangChain is partnering with Scrimba, a code-learning platform with over a million users \n",
      "Through their interactive video format known as scrims, they enable developers to grow their skills in a more fun and immersive way than regular video courses \n",
      "The course will be fully project-based, so you’ll learn the concepts while creating a real-world application \n",
      "Launch is set to mid-October, but a sneak peek of it has already been released .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' LangChain is partnering with Scrimba, a code-learning platform with over a million users ',\n",
       " 'Through their interactive video format known as scrims, they enable developers to grow their skills in a more fun and immersive way than regular video courses ',\n",
       " 'The course will be fully project-based, so you’ll learn the concepts while creating a real-world application ',\n",
       " 'Launch is set to mid-October, but a sneak peek of it has already been released .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_func(langchain_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
